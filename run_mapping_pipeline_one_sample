#!/bin/bash

# This bash script runs a series of commands to generate consensus sequences for 
# newly-sequenced bluetongue virus (BTV) isolates.
#
# It assumes as input Illumina paired end data in 2 files named like this:
# 
# <isolate_name>_R1.fastq.gz
# <isolate_name>_R2.fastq.gz
#
# You pass in the <isolate_name> as a command line argument to the script.
#
# It works by mapping trimmed reads to a set of existing BTV reference sequences downloaded from Genbank
# using bowtie2.  
#
# It then uses the identify_best_segments_from_sam script to identify the best matching existing reference
# sequence, which is defined as the reference sequence with the most reads aligned to it.  
# It does this for all 10 segments.
#
# It then uses a series of samtools and bcftools commands to create new consensus sequences for each of the
# 10 segments and finally remaps reads to these new draft consensus sequences.
#
#
# Dependencies:
#
#    bowtie2
#    samtools
#    bcftools
#    the other scripts in this repository
#    An existing set of btv reference sequences and associated bowtie2 index. 
#      Note that the fasta sequence names are pre-pended with their corresponding segment number
#      E.g.: >s1_AY493686  is a segment 1 reference sequence with NCBI accession AY493686
#
#  Mark Stenglein, Dec, 2015
#

sample_id=$1

# run initial FastQC on input data
fastqc ${sample_id}_R1.fastq.gz ${sample_id}_R2.fastq.gz

# run "pre-procesing" script -> will trim low qual seqs and collapse to unique reads
./run_preprocessing_pipeline_one_sample $sample_id

# post filtering file names (fu = filtered/unique)
fastq_r1=${sample_id}_R1_fu.fastq
fastq_r2=${sample_id}_R2_fu.fastq

# run FastQC assessment on newly trimmed reads
fastqc $fastq_r1 $fastq_r2

# bowtie remaining data against set of BTV ref seqs
bowtie2-build btv_refseq.fasta btv_index
./run_bt_align_paired $fastq_r1 $fastq_r2 btv_index

# extract new fasta file containing best aligned-to seqs for this dataset
./identify_best_segments_from_sam btv_refseq.fasta ${fastq_r1}.btv_index.paired.sam > ${sample_id}_best_10_refseq.fa

# create a new index of just those 10 segments
bowtie2-build ${sample_id}_best_10_refseq.fa ${sample_id}_best_10_index

# re-bowtie data against best 10 BTV ref seqs
./run_bt_align_paired $fastq_r1 $fastq_r2 ${sample_id}_best_10_index

# commands below create "new" consensus sequences

# have to make a .fai file to make mpileup happy
samtools faidx ${sample_id}_best_10_refseq.fa

# mpileup calls variants -> output is a vcf file
samtools mpileup -f ${sample_id}_best_10_refseq.fa -v -u -o ${sample_id}_R1_fu.fastq.${sample_id}_best_10_index.paired_sorted.bam.vcf ${sample_id}_R1_fu.fastq.${sample_id}_best_10_index.paired_sorted.bam

# this script creates a mask file, which is necessary because otherwise bcftools consensus doesn't hanlde positions with no coverage well
# the effect of this mask file will be to create a new draft consensus sequence with Ns at positions with no coverage
./create_mask_file ${sample_id}_R1_fu.fastq.${sample_id}_best_10_index.paired_sorted.bam.vcf > ${sample_id}_R1_fu.fastq.${sample_id}_best_10_index.paired_sorted.bam.vcf.mask

# convert vcf -> compressed vcf to make bcftools happy
bcftools view ${sample_id}_R1_fu.fastq.${sample_id}_best_10_index.paired_sorted.bam.vcf -O z > ${sample_id}_R1_fu.fastq.${sample_id}_best_10_index.paired_sorted.bam.vcf.gz 

# need to make an indexed bcf file to make other bcftools commands happy
bcftools index ${sample_id}_R1_fu.fastq.${sample_id}_best_10_index.paired_sorted.bam.vcf.gz

# bcftools call creates a new vcf file that has consensus bases 
bcftools call -c ${sample_id}_R1_fu.fastq.${sample_id}_best_10_index.paired_sorted.bam.vcf.gz -O b > ${sample_id}_R1_fu.fastq.${sample_id}_best_10_index.paired_sorted.bam.cons.vcf.gz

# need to make an indexed bcf file to make other bcftools commands happy -> here on consensus sequence
bcftools index ${sample_id}_R1_fu.fastq.${sample_id}_best_10_index.paired_sorted.bam.cons.vcf.gz

# bcftools consensus will output a fasta file containing new draft consensus sequence based on called variants
# pipe output through fasta_to_fasta for 1-line fasta format (no longer necessary?) 
# and through remove_trailing_fasta_Ns to strip N characters from beginning and ends of seqs
# and then through a sed to append new_X_draft_sequence to name of fasta record
bcftools consensus -m ${sample_id}_R1_fu.fastq.${sample_id}_best_10_index.paired_sorted.bam.vcf.mask -f ${sample_id}_best_10_refseq.fa ${sample_id}_R1_fu.fastq.${sample_id}_best_10_index.paired_sorted.bam.cons.vcf.gz | 
./remove_trailing_fasta_Ns | 
sed "/^>/ s/$/_new_${sample_id}_draft_sequence/" > ${sample_id}_new_draft_seqs.fa 

# Finally, re-run bowtie against new draft seqs

# create a new index of just those 10 segments
bowtie2-build ${sample_id}_new_draft_seqs.fa ${sample_id}_new_draft_seqs_index

# re-bowtie data against best 10 BTV ref seqs
./run_bt_align_paired $fastq_r1 $fastq_r2 ${sample_id}_new_draft_seqs_index

# collect coverage metrics (mosdepth)
mosdepth ${sample_id}.mosdepth.summary.txt ${sample_id}_R1_fu.fastq.10_best_10_index.paired_sorted.bam

# collect insert size metrics (picard)
java -jar /home/tsherman/picard/build/libs/picard.jar CollectInsertSizeMetrics -I ${sample_id}_R1_fu.fastq.10_best_10_index.paired_sorted.bam -O ${sample_id}_insert_size_metrics.txt -H ${sample_id}_insert_size_histogram.pdf -M 0.5 

# collect duplicates metrics (picard)
java -jar /home/tsherman/picard/build/libs/picard.jar MarkDuplicates -I ${sample_id}_R1_fu.fastq.10_best_10_index.paired_sorted.bam -O ${sample_id}_marked_duplicates.bam -M ${sample_id}_marked_dup_metrics.txt

# generate MultiQC report
multiqc .

# a few final commands to move all newly generated files into a new subdirectory

mkdir pipeline_files_${sample_id}_$(date +%d-%m-%Y)

mv ${sample_id}* pipeline_files_${sample_id}_$(date +%d-%m-%Y)

mv multiqc* pipeline_files_${sample_id}_$(date +%d-%m-%Y)
